{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNf4rUO8UrmiefZTtTipfau",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/06Priya-s/PRODIGY_GA_03/blob/main/Text_NxtWord_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlVpU59NNVGi",
        "outputId": "776903b2-df93-4fc6-f07c-52840e22a2f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting markovify\n",
            "  Downloading markovify-0.9.4.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting unidecode (from markovify)\n",
            "  Downloading Unidecode-1.4.0-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading Unidecode-1.4.0-py3-none-any.whl (235 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: markovify\n",
            "  Building wheel for markovify (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for markovify: filename=markovify-0.9.4-py3-none-any.whl size=18606 sha256=ebed1987e4b6160cab78d4dd4206d5b5750e98c1bec661fc4f0a272905c01438\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/20/eb/1a3fb93f3132f2f9683e4efd834800f80c53aeddf50e84ae80\n",
            "Successfully built markovify\n",
            "Installing collected packages: unidecode, markovify\n",
            "Successfully installed markovify-0.9.4 unidecode-1.4.0\n"
          ]
        }
      ],
      "source": [
        "! pip install markovify"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Markov Chain Text Generator\n",
        "# This implementation uses character-level Markov chains to generate text\n",
        "\n",
        "from collections import defaultdict\n",
        "import random\n",
        "import requests"
      ],
      "metadata": {
        "id": "kyQ5TUZ9P81I"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MarkovChain:\n",
        "    def __init__(self, order=2):\n",
        "        \"\"\"\n",
        "        Initialize the Markov Chain with a given order.\n",
        "        Order determines how many previous characters to consider for prediction.\n",
        "        \"\"\"\n",
        "        self.order = order\n",
        "        self.model = defaultdict(lambda: defaultdict(int))\n",
        "        self.start_states = []\n",
        "\n",
        "    def train(self, text):\n",
        "        \"\"\"\n",
        "        Train the model on the given text\n",
        "        \"\"\"\n",
        "        if len(text) <= self.order:\n",
        "            return\n",
        "\n",
        "        for i in range(len(text) - self.order):\n",
        "            # Get the current state (sequence of 'order' characters)\n",
        "            current_state = text[i:i+self.order]\n",
        "\n",
        "            # Get the next character\n",
        "            next_char = text[i+self.order]\n",
        "\n",
        "            # Update the model\n",
        "            self.model[current_state][next_char] += 1\n",
        "\n",
        "            # Track possible start states\n",
        "            if i == 0:\n",
        "                self.start_states.append(current_state)\n",
        "\n",
        "    def generate(self, length=100, start_state=None):\n",
        "        \"\"\"\n",
        "        Generate text of specified length\n",
        "        \"\"\"\n",
        "        if not self.model:\n",
        "            return \"\"\n",
        "\n",
        "        # Choose a random start state if none provided\n",
        "        if start_state is None:\n",
        "            current_state = random.choice(self.start_states)\n",
        "        else:\n",
        "            current_state = start_state[:self.order]\n",
        "            if current_state not in self.model:\n",
        "                current_state = random.choice(self.start_states)\n",
        "\n",
        "        generated_text = current_state\n",
        "\n",
        "        for _ in range(length - self.order):\n",
        "            # Get possible next characters and their counts\n",
        "            next_chars = self.model[current_state]\n",
        "\n",
        "            if not next_chars:\n",
        "                break\n",
        "\n",
        "            # Convert counts to probabilities\n",
        "            total = sum(next_chars.values())\n",
        "            probs = {char: count/total for char, count in next_chars.items()}\n",
        "\n",
        "            # Choose next character based on probabilities\n",
        "            next_char = random.choices(\n",
        "                list(probs.keys()),\n",
        "                weights=list(probs.values()),\n",
        "                k=1\n",
        "            )[0]\n",
        "\n",
        "            generated_text += next_char\n",
        "\n",
        "            # Update current state\n",
        "            current_state = generated_text[-self.order:]\n",
        "\n",
        "        return generated_text"
      ],
      "metadata": {
        "id": "j7GV4gusQIqu",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download some sample text (Alice in Wonderland)\n",
        "url = \"https://www.gutenberg.org/files/11/11-0.txt\"\n",
        "response = requests.get(url)\n",
        "text = response.text\n",
        "\n",
        "# Clean the text a bit (keep it simple)\n",
        "text = text.replace('\\r', ' ').replace('\\n', ' ')\n",
        "text = text[:10000]  # Just use the first part for this example\n",
        "\n",
        "# Create and train the model\n",
        "markov = MarkovChain(order=3)\n",
        "markov.train(text)\n",
        "\n",
        "# Generate some text\n",
        "generated_text = markov.generate(length=200)\n",
        "print(\"Generated Text:\")\n",
        "print(generated_text)\n",
        "\n",
        "# Try with different order\n",
        "print(\"\\nTrying with order=10:\")\n",
        "markov = MarkovChain(order=10)\n",
        "markov.train(text)\n",
        "generated_text = markov.generate(length=10000)\n",
        "formatted_text = generated_text.replace('. ', '.\\n')\n",
        "print(formatted_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTdtnzcEvzaD",
        "outputId": "9d546da3-a517-4e53-a633-65991edd8adf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text:\n",
            "*** START OF THE PROJECT GUTENBERG EBOOK 11 ***    *            *    *     *   *   Alice had picking do _very some see it.  In a passaged ope.”  Do came a rand to look fill it Send? “I wouldn’t a long\n",
            "\n",
            "Trying with order=10:\n",
            "*** START OF THE PROJECT GUTENBERG EBOOK 11 ***  [Illustration]     Alice’s Adventures in Wonderland  by Lewis Carroll  THE MILLENNIUM FULCRUM EDITION 3.0  Contents   CHAPTER IX.\n",
            "   The Mock Turtle’s Story  CHAPTER XI.\n",
            "   Who Stole the Tarts?  CHAPTER IV.\n",
            "   The Rabbit was no longer to be seen: she found herself in a long, low hall, which was lit up by a row of lamps hanging from the roof.\n",
            " There were doors all round the hall, but they were all locked; and when Alice had no idea what Latitude or Longitude either, but the Rabbit-Hole  CHAPTER VI.\n",
            "   Pig and Pepper  CHAPTER I.\n",
            "    Down the Rabbit-Hole   Alice was not a _very_ good opportunity for showing off her knowledge, as there was nothing else to do, so Alice ventured to taste it, and finding it very nice, (it had, in fact, a sort of mixed flavour of cherry-tart, custard, pine-apple, roast turkey, toffee, and hot buttered toast,) she very soon finished it off.\n",
            " *      *      *      *      *      *      *      *      *   “What a curious feeling!” said Alice; “I must be getting somewhere.”  Down, down, down.\n",
            "There was nothing on it except a tiny golden key in the lock, and to her great delight it fitted!  Alice opened the door and found that it led into a small passage, and the fall was over.\n",
            " Alice was not a _very_ good opportunity for showing off her knowledge, as there was nothing of tumbling down a very deep, or she fell past it.\n",
            " “Well!” thought poor Alice, “it would be of very little use without my shoulders.\n",
            "Oh, how I wish I could shut up like a telescope.”  And so it was indeed: she was now only ten inches high: she tried to curtsey as she spoke—fancy _curtseying_ as you’re falling through the doorway; “and even if my head would go through,” thought Alice “without pictures hung upon pegs.\n",
            "She took down and looked at the sides of the well, and noticed that they were all locked; and when Alice had no idea what Latitude was, or Longitude I’ve got to?” (Alice had learnt several things of this sort in her lessons in the schoolroom, and though this was not a _very_ good opportunity for showing off her knowledge, as there was no one to listen to her, still it was good practice to say it over) “—yes, that’s about this; “for it might belong to one of the doors of the hall; but, alas! either the locks were too large, or the key was too small, but at any rate a book of rules for shutting up like a telescopes: this time?” she said aloud.\n",
            "“I must be getting somewhere.”  Down, down, down.\n",
            "There was no one to listen to her, still it was good practice to say it over) “—yes, that’s about this; “for it might belong to one of the cupboards as she fell very slowly, for she could not remember ever having seen such a thing.\n",
            " After a while\n"
          ]
        }
      ]
    }
  ]
}